{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -U langchain_community langchain-openai langchain-anthropic langchain langgraph bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "  \"\"\"Takes in a file path and reads that file line by line and returns the content as a string.\"\"\"\n",
    "  with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "  return ''.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write File Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_path, file_content):\n",
    "    \"\"\"Takes in a file path and file content variable to write to the file\"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(file_content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset original files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnm_original_xml = read_file(file_path=\"main_activity_layout_do_not_modify.xml\")\n",
    "dnm_original_main_activity = read_file(file_path=\"main_activity_do_not_modify.kt\")\n",
    "\n",
    "write_file(file_path=\"main_activity_layout.xml\", file_content=dnm_original_xml)\n",
    "write_file(file_path=\"main_activity.kt\", file_content=dnm_original_main_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Migration & Files to Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migrationInstructions = read_file(file_path=\"button_migration_doc.md\")\n",
    "\n",
    "to_migrate_array = [\"main_activity_layout.xml\", \"main_activity.kt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model for Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class code(BaseModel):\n",
    "    \"\"\"Schema for code outputs for migrations.\"\"\"\n",
    "\n",
    "    prefix: str = Field(description=\"Description of what was changed and why\")\n",
    "    code: str = Field(description=\"Entire code block with migrations performed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "## Uncomment to run\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "# _set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Prompt for code generation\n",
    "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"<instructions> You are a coding assistant with expertise in Android, Kotlin, and XML based UI. \\n \n",
    "            You are tasked with migrating code for an Android project that impacts the XML UI and kotlin code. \\n\n",
    "            Here is documentation on the migration to be performed:  \\n ------- \\n  {context} \\n ------- \\n\n",
    "            Migrate the provided code and output the entire class with the migrations peformed.\\n\n",
    "            Ensure that the code you provide only modifies what is necessary for the migration.\\n\n",
    "            Ensure all code that is output is ready to be executed.\\n\n",
    "            Structure your answer: 1) a prefix describing what you changed and why 2) The entire code block  \\n\n",
    "            Invoke the code tool to structure the output correctly. </instructions> \\n Here is the migration to be performed:\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prompt for code review\n",
    "code_review_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"<instructions> You are a coding reviewer with expertise in Android, Kotlin, and XML based UI. \\n \n",
    "            You are evaluating code tasked with migrating code for an Android project that impacts the XML UI and kotlin code. \\n\n",
    "            Here is documentation on the migration to be performed:  \\n ------- \\n  {context} \\n ------- \\n\n",
    "            Review the provided code and ensure that all migrations are performed and everything else remains unmodified\\n\n",
    "            Provide feedback on the modifcations in list form.\\n\n",
    "            If everything looks correct, output: correct\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "expt_llm = \"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(temperature=0, model=expt_llm)\n",
    "\n",
    "# Code Gen Chain\n",
    "code_gen_chain = code_gen_prompt | llm.with_structured_output(code)\n",
    "\n",
    "# Code Review Chain \n",
    "code_review_chain = code_review_prompt | llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test\n",
    "## Uncomment to run\n",
    "# solution = code_gen_chain.invoke({\"context\": migrationInstructions, \"messages\": [(\"user\", original_xml)]})\n",
    "# solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        error : Binary flag for control flow to indicate whether test error was tripped\n",
    "        messages : With user question, error messages, reasoning\n",
    "        generation : Code solution\n",
    "        iterations : Number of tries\n",
    "    \"\"\"\n",
    "\n",
    "    error: str\n",
    "    messages: List\n",
    "    generation: str\n",
    "    iterations: int\n",
    "    file_iteration: int = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter\n",
    "\n",
    "# Max tries\n",
    "max_iterations = 2\n",
    "# Reflect\n",
    "# flag = 'reflect'\n",
    "flag = \"do not reflect\"\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def file_selection(state: GraphState):\n",
    "    \"\"\"\n",
    "    Prompts the LLM with the next file to be migrated\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "    \n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "    file_iteration = state[\"file_iteration\"] + 1\n",
    "    \n",
    "    file_selected = to_migrate_array[file_iteration]\n",
    "    print(f\"---SELECTING FILE: {file_selected}---\")\n",
    "    \n",
    "    opened_file = read_file(file_path=file_selected)\n",
    "    # {\"messages\": [(\"user\", original_xml)], \"iterations\": 0, \"error\": \"\"}\n",
    "    return {\"messages\": [(\"user\", opened_file)], \"iterations\": 0, \"error\": \"\", \"file_iteration\": file_iteration}\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "    file_iteration = state[\"file_iteration\"]\n",
    "\n",
    "    # We have been routed back to generation with an error\n",
    "    if error == \"yes\":\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Now, try again. Invoke the code tool to structure the output with a prefix and code block:\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Solution\n",
    "    print(f\"---GENERATING CODE FOR FILE: {to_migrate_array[file_iteration]}\")\n",
    "    code_solution = code_gen_chain.invoke(\n",
    "        {\"context\": migrationInstructions, \"messages\": messages}\n",
    "    )\n",
    "    \n",
    "    messages += [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            f\"{code_solution.prefix} Code: {code_solution.code}\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Increment\n",
    "    iterations = iterations + 1\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations, \"file_iteration\": file_iteration}\n",
    "\n",
    "\n",
    "def code_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code against the migration guide ensuring that only the necessary changes were made.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---REVIEWING CODE FOR ACCURACY---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    file_iteration = state[\"file_iteration\"]\n",
    "    \n",
    "    # TODO, run unit tests \n",
    "    \n",
    "    review_output = code_review_chain.invoke(\n",
    "        {\"context\": migrationInstructions, \"messages\": messages}\n",
    "    )\n",
    "    \n",
    "    feedback = review_output.content\n",
    "    \n",
    "    feedback_error = \"no\"\n",
    "    if(not feedback.endswith(\"correct\")):\n",
    "        feedback_error = \"yes\"\n",
    "    \n",
    "    messages += [(\"reviewer\", f\"Here is feedback on the performed changes: {feedback}\")]\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations, \"error\":feedback_error, \"file_iteration\": file_iteration}\n",
    "\n",
    "\n",
    "def reflect(state: GraphState):\n",
    "    \"\"\"\n",
    "    Reflect on errors\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---REFLECT ON CODE SOLUTION & FEEDBACK---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    file_iteration = state[\"file_iteration\"]\n",
    "\n",
    "    # Prompt reflection\n",
    "\n",
    "    # Add reflection\n",
    "    reflections = code_gen_chain.invoke(\n",
    "        {\"context\": migrationInstructions, \"messages\": messages}\n",
    "    )\n",
    "    messages += [(\"assistant\", f\"Here are reflections on the changes performed: {reflections}\")]\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations, \"file_iteration\": file_iteration}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_finish(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    file_iteration = state[\"file_iteration\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "\n",
    "    if error != \"yes\" or iterations == max_iterations:\n",
    "        # save current file \n",
    "        write_file(file_path=to_migrate_array[file_iteration], file_content=code_solution.code)\n",
    "        \n",
    "        if(file_iteration==len(to_migrate_array)-1):\n",
    "            print(\"---DECISION: FINISH---\")\n",
    "            return \"end\"\n",
    "        else:\n",
    "            print(\"---DECISION: NEXT---\")\n",
    "            return \"next\"\n",
    "       \n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        if flag == \"reflect\":\n",
    "            return \"reflect\"\n",
    "        else:\n",
    "            return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"file_selection\", file_selection)\n",
    "workflow.add_node(\"generate\", generate)  # generation solution\n",
    "workflow.add_node(\"check_code\", code_check)  # check code\n",
    "workflow.add_node(\"reflect\", reflect)  # reflect\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"file_selection\")\n",
    "workflow.add_edge(\"file_selection\", \"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"next\":\"file_selection\",\n",
    "        \"reflect\": \"reflect\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"reflect\", \"generate\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = app.invoke({\"messages\": [], \"iterations\": 0, \"error\": \"\", \"file_iteration\": -1})\n",
    "\n",
    "\n",
    "solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
